:require /C:/data-integration/drivers/postgresql-42.2.22.jar
val products=spark.read.format("jdbc").option("url","jdbc:postgresql://localhost:5432/postgres").option("driver","org.postgresql.Driver").option("dbtable","public.products").option("user","postgres").option("password","1").load()
val products1=products.select('pro_code,'man_code,'pro_name,'pro_theme).filter(col("pro_type").contains("PUZZLE"))
val products2=products1.withColumnRenamed("man_code","id_js_man").withColumnRenamed("pro_name","name").withColumn("dummy",lit("N/A")).withColumn("lastupdate",lit(current_timestamp())).withColumnRenamed("pro_theme","theme").withColumnRenamed("pro_code","id_js_prod").withColumn("start_date",lit("1900-01-01").cast("date")).withColumn("end_date",lit("2199-12-31").cast("date")).withColumn("version",lit(1)).withColumn("current",lit("Y"))
import org.apache.spark.sql.expressions.Window
val id=Window.partitionBy('dummy).orderBy('id_js_prod)
val products3=products2.withColumn("id", rank over id)
val products4=products3.select('id,'name,'theme,'id_js_prod,'id_js_man,'start_date,'end_date,'version,'current,'lastupdate)
val lk_puzzles=spark.read.format("jdbc").option("url","jdbc:postgresql://localhost:5432/js_dw").option("driver","org.postgresql.Driver").option("dbtable","public.lk_puzzles").option("user","postgres").option("password","1").load().cache()
lk_puzzles.count()
val lk_puzzles1=lk_puzzles.na.drop()
val lk_puzzles2=lk_puzzles1.union(products4)
val lk_puzzles3=lk_puzzles2.dropDuplicates("theme","id_js_prod")
val lk_puzzles4=lk_puzzles3.groupBy('id_js_prod.as("prodid")).count().filter("count > 1")
val lk_puzzles5=lk_puzzles3.join(lk_puzzles4, lk_puzzles3("id_js_prod") === lk_puzzles4("prodid"),"inner")
val lk_puzzles6=lk_puzzles5.withColumn("current", when(lk_puzzles5("lastupdate") < current_timestamp(), "N").otherwise("Y")).withColumn("version", when(lk_puzzles5("lastupdate") < current_timestamp(), $"version").otherwise($"version"+1)).withColumn("start_date", when(lk_puzzles5("lastupdate") < current_timestamp(), $"start_date").otherwise(current_date())).withColumn("end_date", when(lk_puzzles5("lastupdate") < current_timestamp(), current_date()).otherwise($"end_date"))
val lk_puzzles7=lk_puzzles6.drop("prodid","count")
val lk_puzzles8=products4.union(lk_puzzles7)
val lk_puzzles9=lk_puzzles8.sort('id_js_prod,'lastupdate,desc("version"))
val lk_puzzles10=lk_puzzles9.dropDuplicates("theme","id_js_prod","current")
val lk_puzzles11=lk_puzzles10.drop('id).withColumn("dummy",lit("NA"))
import org.apache.spark.sql.expressions.Window
val id=Window.partitionBy('dummy).orderBy('version,'id_js_prod)
val lk_puzzles12=lk_puzzles11.withColumn("id", rank over id)
val lk_puzzles13=lk_puzzles12.select('id,'name,'theme,'id_js_prod,'id_js_man,'start_date,'end_date,'version,'current,'lastupdate)
val lk_puzzles14=lk_puzzles13.union(Seq((0,"N/A","N/A",0,0,null,null,1,"Y",null)).toDF)
lk_puzzles14.write.format("jdbc").mode("overwrite").option("delete from",true).option("url","jdbc:postgresql://localhost:5432/js_dw").option("driver","org.postgresql.Driver").option("dbtable","public.lk_puzzles").option("user","postgres").option("password","1").save()