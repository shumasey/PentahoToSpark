:require /C:/data-integration/drivers/postgresql-42.2.22.jar
val cities=spark.read.format("jdbc").option("url","jdbc:postgresql://localhost:5432/postgres").option("driver","org.postgresql.Driver").option("dbtable","public.cities").option("user","postgres").option("password","1").load()
val countries=spark.read.format("jdbc").option("url","jdbc:postgresql://localhost:5432/postgres").option("driver","org.postgresql.Driver").option("dbtable","public.countries").option("user","postgres").option("password","1").load()
val regions=cities.join(countries,cities("cou_id") === countries("cou_id"),"inner").drop("cou_id").withColumn("country_name",trim(col("country_name")))
:require /C:/pdi_files/jars/spark-excel_2.12-0.13.7.jar
import com.crealytics.spark.excel._
// val regions0=spark.read.format("com.crealytics.spark.excel").option("header",true).load("C:/pdi_files/input/regions.xls")
// val regions0=spark.read.format("com.crealytics.spark.excel").option("header",true).load("C:/pdi_files/input/regions2008.xls")
val regions0=spark.read.format("com.crealytics.spark.excel").option("header",true).load("C:/pdi_files/input/myregions.xls")
val regions1=regions.join(regions0,regions("country_name") === regions0("country"),"left").drop("country")
//val regions2=regions1.withColumn("version_1",lit(null)).withColumn("country_1",lit(null)).withColumn("start_date",lit("1900-01-01").cast("date")).withColumn("end_date",lit("2199-12-31").cast("date")).withColumn("version",lit(1)).withColumn("dummy",lit("N/A")).withColumnRenamed("country_name","country").withColumn("current",lit(current_timestamp()))
//import org.apache.spark.sql.expressions.Window
//val id=Window.partitionBy('dummy).orderBy('country,'city_name)
//val regions3=regions2.withColumn("id", rank over id)
//val regions4=regions3.select('id,'start_date,'end_date,'version,'country_1,'version_1,'country,'region,'current)
//val date = scala.io.StdIn.readLine("Put the date in format YYYY/MM/DD or press ENTER for today ")
//val date1=Seq(date).toDF("inputdate")
//val date2=date1.withColumn("changedate", when(length('inputdate) === 0, current_date()).otherwise(to_date('inputdate, "yyyy/MM/dd")))
//val lk_regions_2=spark.read.format("jdbc").option("url","jdbc:postgresql://localhost:5432/js_dw").option("driver","org.postgresql.Driver").option("dbtable","public.lk_regions_2").option("user","postgres").option("password","1").load().cache()
//lk_regions_2.count()
//val lk_regions_21=lk_regions_2.na.drop(Seq("country"))
//val lk_regions_22=lk_regions_21.union(regions4)
//val lk_regions_23=lk_regions_22.dropDuplicates("region","country")
//val lk_regions_24=lk_regions_23.groupBy('country.as("cntr")).count().filter("count > 1")
//val lk_regions_25=lk_regions_24.join(date2)
//val lk_regions_26=lk_regions_23.join(lk_regions_25, lk_regions_23("country") === lk_regions_25("cntr"),"inner")
//val lk_regions_27=lk_regions_26.withColumn("version", when(lk_regions_26("current") < current_timestamp(), $"version").otherwise($"count")).withColumn("start_date", when(lk_regions_26("current") < current_timestamp(), $"start_date").otherwise(lk_regions_26("changedate"))).withColumn("end_date", when(lk_regions_26("current") < current_timestamp() && lk_regions_26("end_date") === "2199-12-31", lk_regions_26("changedate")).otherwise($"end_date"))
//val lk_regions_28=lk_regions_27.drop("cntr","count","inputdate","changedate")
//val lk_regions_29=regions4.union(lk_regions_28)
//val lk_regions_210=lk_regions_29.sort('country,'current,desc("version"))
//val lk_regions_211=lk_regions_210.dropDuplicates("region","country")
//val lk_regions_212=lk_regions_211.drop('id).withColumn("dummy",lit("NA"))
//import org.apache.spark.sql.expressions.Window
//val id=Window.partitionBy('dummy).orderBy('version,'country)
//val lk_regions_213=lk_regions_212.withColumn("id", rank over id)
//val lk_regions_214=lk_regions_213.select('id,'start_date,'end_date,'version,'country_1,'version_1,'country,'region,'current)
//val lk_regions_215=lk_regions_214.union(Seq((0,null,null,1,null,null,null,null,null)).toDF)
//lk_regions_215.write.format("jdbc").mode("overwrite").option("delete from",true).option("url","jdbc:postgresql://localhost:5432/js_dw").option("driver","org.postgresql.Driver").option("dbtable","public.lk_regions_2").option("user","postgres").option("password","1").save()